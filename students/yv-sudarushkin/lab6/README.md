# Лабораторная работа №6. Регрессия

## Описание задачи
Цель данной лабораторной работы:
1. Реализовать линейную регрессию с использованием гребневой регуляризации (Ridge Regression) через сингулярное разложение.
2. Оптимизировать параметр регуляризации $\(\tau\)$.
3. Сравнить результаты с эталонной реализацией линейной регрессии из библиотеки `scikit-learn`.

## Шаги выполнения

### 1. Выбор датасета
Для экспериментов используется датасет **California Housing**, который предоставляет данные о стоимости жилья в Калифорнии и соответствующих признаках (площадь, количество комнат, близость к океану и т.д.).

### 2. Предварительная обработка данных
Данные масштабируются с использованием `MinMaxScaler` как для признаков (X), так и для целевой переменной (y). Масштабирование необходимо для стабильной работы моделей.

### 3. Эталонная модель линейной регрессии
Реализована с использованием `LinearRegression` из `scikit-learn`. Вычислены следующие метрики:
- Среднеквадратичная ошибка (MSE): $0.022$
- R2 - метрика: $0.607$

### 4. Линейная регрессия с SVD и $\tau = 0$
Собственная реализация линейной регрессии. Вычислены метрики:
- Среднеквадратичная ошибка (MSE): $0.612$
- R2 - метрика: $0.537$

### 5. Оптимизация $\tau$
Реализован поиск оптимального значения $\tau$ на основе минимизации валидационной ошибки. Итерации представлены графиком, где ось X — значения $\tau$, ось Y — валидационная ошибка. Оптимальное значение $\tau$: 0.350.

Метрики для оптимизированной модели:
- Среднеквадратичная ошибка (MSE): $0.589$
- R2 - метрика: $0.555$ _(Точно достойно 5-ки)_

## Скриншоты и результаты
### Пример визуализации предсказаний

![image](https://github.com/user-attachments/assets/860c78cc-cd9c-4451-95dd-f5e146d029a6)

### График оптимизации $\tau$

![image](https://github.com/user-attachments/assets/424842c1-661b-4f49-b452-f22c882f1228)

### Расчет метрик и вывод графиков
[jupyter](source/main.ipynb)

### Код собственной реализации линейной регресси
[python-код](source/LinRegressions.py)

## Выводы
1. Эталонная линейная регрессия показывает средние метрики, показывая применимость линейной регрессии к данном датасету.
2. Линейная регрессия с $\(\tau = 0\)$ имеет результаты примерно на 9% хуже эталонной, но это показывает что свое решение справляется с задачей регрессии.
3. Оптимизация с подбором $\tau$ позволяет немного улучшить результат, подобрав оптимальный параметр регуляризации. Оптимальное значение $\tau$: 0.350. Стоит заметить, что оно также зависит от корреляции обучаемой выборки и валидационной. При другом random_state в train_test_split получится другой $\tau$ 

