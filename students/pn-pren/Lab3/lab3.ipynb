{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\pavel\\.cache\\kagglehub\\datasets\\yasserh\\titanic-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + '/Titanic-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Survived', axis=1).values\n",
    "y = df['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, criterion='entropy', max_depth=None, min_samples_split=2):\n",
    "        self.criterion = criterion\n",
    "        self.tree = None\n",
    "        self.class_probabilities = None\n",
    "        self.majority_class = None\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        valid_indices = ~np.isnan(features).any(axis=1)\n",
    "        features = features[valid_indices]\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "        unique_classes, counts = np.unique(labels, return_counts=True)\n",
    "        self.majority_class = unique_classes[np.argmax(counts)]\n",
    "        self.class_probabilities = counts / len(labels)\n",
    "\n",
    "        self.tree = self._id3_classification(features, labels, depth=0, max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"Время обучения: {end_time - start_time:.4f} секунд\")\n",
    "\n",
    "    def _id3_classification(self, features, labels, depth, max_depth, min_samples_split):\n",
    "        # макс глубина -> класс, который часто встречается в ноде + вероятности классов\n",
    "        if max_depth is not None and depth >= max_depth:\n",
    "            counts = np.bincount(labels)\n",
    "            probabilities = counts / len(labels)\n",
    "            return counts.argmax(), None, None, None, probabilities\n",
    "\n",
    "        # Если все метки одинаковы -> возвращаем класс + вероятности\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) == 1:\n",
    "            counts = np.bincount(labels)\n",
    "            probabilities = counts / len(labels)\n",
    "            return counts.argmax(), None, None, None, probabilities\n",
    "        \n",
    "        if len(labels) < min_samples_split:\n",
    "            counts = np.bincount(labels)\n",
    "            probabilities = counts / len(labels)\n",
    "            return counts.argmax(), None, None, None, probabilities\n",
    "\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_info_gain = -np.inf\n",
    "\n",
    "        for feature_index in range(features.shape[1]):\n",
    "            thresholds = np.unique(features[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                mask = features[:, feature_index] <= threshold\n",
    "\n",
    "                # Пропускаем разделения, которые не делят данные\n",
    "                if np.sum(mask) == 0 or np.sum(~mask) == 0:\n",
    "                    continue\n",
    "\n",
    "                if self.criterion == 'entropy':\n",
    "                    info_gain = self._calculate_information_gain(labels, mask)\n",
    "                else:\n",
    "                    info_gain = self._d_criterion(labels, mask)\n",
    "\n",
    "                if info_gain > best_info_gain:\n",
    "                    best_info_gain = info_gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        if best_feature is None:\n",
    "            counts = np.bincount(labels)\n",
    "            probabilities = counts / len(labels)\n",
    "            return counts.argmax(), None, None, None, probabilities\n",
    "\n",
    "        mask = features[:, best_feature] <= best_threshold\n",
    "\n",
    "        if np.sum(mask) == 0 or np.sum(~mask) == 0:\n",
    "            counts = np.bincount(labels)\n",
    "            probabilities = counts / len(labels)\n",
    "            return counts.argmax(), None, None, None, probabilities\n",
    "\n",
    "        left_subtree = self._id3_classification(\n",
    "            features[mask], labels[mask], depth=depth + 1, max_depth=max_depth, min_samples_split=min_samples_split\n",
    "        )\n",
    "        right_subtree = self._id3_classification(\n",
    "            features[~mask], labels[~mask], depth=depth + 1, max_depth=max_depth, min_samples_split=min_samples_split\n",
    "        )\n",
    "        left_probabilities = len(labels[mask]) / len(labels)\n",
    "\n",
    "        return (best_feature, best_threshold, left_subtree, right_subtree, left_probabilities)\n",
    "\n",
    "    def _calculate_information_gain(self, labels, mask):\n",
    "        total_entropy = self._entropy(labels)\n",
    "        left_entropy = self._entropy(labels[mask])\n",
    "        right_entropy = self._entropy(labels[~mask])\n",
    "\n",
    "        weighted_entropy = (len(labels[mask]) / len(labels)) * left_entropy + (len(labels[~mask]) / len(labels)) * right_entropy\n",
    "        return total_entropy - weighted_entropy\n",
    "\n",
    "    def _d_criterion(self, labels, mask):\n",
    "        return self._calculate_information_gain(labels, mask)\n",
    "\n",
    "    def _entropy(self, labels):\n",
    "        if len(labels) == 0:\n",
    "            return 0\n",
    "        _, counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        return -np.sum(probabilities * np.log2(probabilities + 1e-10))  # Прибавка для избежания логарифма от нуля\n",
    "\n",
    "    def _predict(self, sample, tree):        \n",
    "        feature, threshold, left_subtree, right_subtree, _ = tree\n",
    "\n",
    "        if threshold is None:\n",
    "            return feature  # Здесь 'feature' — это фактически 'class_label'\n",
    "        \n",
    "        if not np.isnan(sample).any():\n",
    "            if sample[feature] <= threshold:\n",
    "                return self._predict(sample, left_subtree)\n",
    "            else:\n",
    "                return self._predict(sample, right_subtree)\n",
    "        else:\n",
    "            return self.majority_class\n",
    "        \n",
    "    def _predict_batch(self, samples, tree):\n",
    "        return np.array([self._predict(sample, tree) for sample in samples])\n",
    "\n",
    "    def predict(self, samples):\n",
    "        start_time = time.perf_counter()\n",
    "        predictions = self._predict_batch(samples, self.tree)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"Время предсказания: {end_time - start_time:.4f} секунд\")\n",
    "        return predictions\n",
    "\n",
    "    def _prune_tree(self, tree, validation_features, validation_labels):\n",
    "        feature, threshold, left_subtree, right_subtree, _ = tree\n",
    "\n",
    "        if threshold is None:\n",
    "            return tree\n",
    "\n",
    "        # Разделяем валидационные данные согласно текущему узлу\n",
    "        mask = validation_features[:, feature] <= threshold\n",
    "        left_val_features = validation_features[mask]\n",
    "        left_val_labels = validation_labels[mask]\n",
    "        right_val_features = validation_features[~mask]\n",
    "        right_val_labels = validation_labels[~mask]\n",
    "\n",
    "        # Рекурсивно обрезаем поддеревья\n",
    "        if left_subtree is not None:\n",
    "            left_pruned = self._prune_tree(left_subtree, left_val_features, left_val_labels)\n",
    "        else:\n",
    "            left_pruned = left_subtree\n",
    "\n",
    "        if right_subtree is not None:\n",
    "            right_pruned = self._prune_tree(right_subtree, right_val_features, right_val_labels)\n",
    "        else:\n",
    "            right_pruned = right_subtree\n",
    "\n",
    "        pruned_tree = (feature, threshold, left_pruned, right_pruned, _)\n",
    "\n",
    "        # Сравниваем точность до и после обрезки\n",
    "        original_accuracy = self._calculate_accuracy(tree, validation_features, validation_labels)\n",
    "        pruned_accuracy = self._calculate_accuracy(pruned_tree, validation_features, validation_labels)\n",
    "\n",
    "        # Если обрезка улучшает или сохраняет точность, возвращаем обрезанное дерево\n",
    "        if pruned_accuracy >= original_accuracy:\n",
    "            return pruned_tree\n",
    "        else:\n",
    "            # Замена узла на листовой с большинством меток в текущем валидационном наборе\n",
    "            class_label = self._get_majority_class(validation_labels)\n",
    "            return (class_label, None, None, None, None)\n",
    "\n",
    "    def _get_majority_class(self, labels):\n",
    "        if len(labels) == 0:\n",
    "            return self.majority_class\n",
    "        unique_classes, counts = np.unique(labels, return_counts=True)\n",
    "        return unique_classes[np.argmax(counts)]\n",
    "\n",
    "    def _calculate_accuracy(self, tree, validation_features, validation_labels):\n",
    "        predictions = self._predict_batch(validation_features, tree)\n",
    "        return np.mean(predictions == validation_labels)\n",
    "\n",
    "    def prune(self, validation_features, validation_labels):\n",
    "        start_time = time.perf_counter()\n",
    "        self.tree = self._prune_tree(self.tree, validation_features, validation_labels)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"Время обрезки дерева: {end_time - start_time:.4f} секунд\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_val):\n",
    "    correct_predictions = (y_pred == y_val).sum()  \n",
    "    total_predictions = len(y_val) \n",
    "    return correct_predictions / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 0.3640 секунд\n",
      "Время предсказания: 0.0027 секунд\n",
      "Точность модели до обрезки: 75.42%\n",
      "Время обрезки дерева: 0.0290 секунд\n",
      "Время предсказания: 0.0027 секунд\n",
      "Точность модели после обрезки: 75.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavel\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\pavel\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42\n",
    ")  \n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Точность модели до обрезки: {accuracy * 100:.2f}%\")\n",
    "\n",
    "clf.prune(X_val, y_val)\n",
    "\n",
    "pruned_predictions = clf.predict(X_test)\n",
    "\n",
    "# Оценка точности после обрезки\n",
    "pruned_accuracy = np.mean(pruned_predictions == y_test)\n",
    "print(f\"Точность модели после обрезки: {pruned_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 0.4178 секунд\n",
      "Время предсказания: 0.0037 секунд\n",
      "Точность модели до обрезки: 75.42%\n",
      "Время обрезки дерева: 0.0428 секунд\n",
      "Время предсказания: 0.0039 секунд\n",
      "Точность модели после обрезки: 75.98%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=42\n",
    ")  \n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='d_criterion', max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Точность модели до обрезки: {accuracy * 100:.2f}%\")\n",
    "\n",
    "clf.prune(X_val, y_val)\n",
    "\n",
    "pruned_predictions = clf.predict(X_test)\n",
    "\n",
    "pruned_accuracy = np.mean(pruned_predictions == y_test)\n",
    "print(f\"Точность модели после обрезки: {pruned_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.25, random_state=42, stratify=y_train_full\n",
    ")  # 0.25 * 0.8 = 0.2 от исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения модели Gini: 0.0018 секунд\n",
      "Время обучения модели Entropy: 0.0018 секунд\n"
     ]
    }
   ],
   "source": [
    "def train_model(criterion, X_train, y_train):\n",
    "    start_time = time.perf_counter()\n",
    "    model = SklearnDecisionTreeClassifier(criterion=criterion, max_depth=10, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.perf_counter()\n",
    "    training_time = end_time - start_time\n",
    "    return model, training_time\n",
    "\n",
    "model_gini, time_gini_train = train_model('gini', X_train, y_train)\n",
    "model_entropy, time_entropy_train = train_model('entropy', X_train, y_train)\n",
    "\n",
    "print(f\"Время обучения модели Gini: {time_gini_train:.4f} секунд\")\n",
    "print(f\"Время обучения модели Entropy: {time_entropy_train:.4f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели Gini до обрезки: 76.54%\n",
      "Время предсказания модели Gini: 0.0004 секунд\n",
      "Точность модели Entropy до обрезки: 77.65%\n",
      "Время предсказания модели Entropy: 0.0002 секунд\n"
     ]
    }
   ],
   "source": [
    "def predict_model(model, X_test, y_test):\n",
    "    start_time = time.perf_counter()\n",
    "    predictions = model.predict(X_test)\n",
    "    end_time = time.perf_counter()\n",
    "    prediction_time = end_time - start_time\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return predictions, prediction_time, accuracy\n",
    "\n",
    "pred_gini, time_gini_pred, acc_gini = predict_model(model_gini, X_test, y_test)\n",
    "pred_entropy, time_entropy_pred, acc_entropy = predict_model(model_entropy, X_test, y_test)\n",
    "\n",
    "print(f\"Точность модели Gini до обрезки: {acc_gini * 100:.2f}%\")\n",
    "print(f\"Время предсказания модели Gini: {time_gini_pred:.4f} секунд\")\n",
    "\n",
    "print(f\"Точность модели Entropy до обрезки: {acc_entropy * 100:.2f}%\")\n",
    "print(f\"Время предсказания модели Entropy: {time_entropy_pred:.4f} секунд\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeRegressor:\n",
    "    def __init__(self, min_samples_split):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        self.class_distribution = None\n",
    "        self._highest_prob = -1\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        # Remove rows with any NaN values\n",
    "        valid_idx = ~np.isnan(features).any(axis=1)\n",
    "        features, targets = features[valid_idx], targets[valid_idx]\n",
    "\n",
    "        # Calculate class distribution\n",
    "        _, counts = np.unique(targets, return_counts=True)\n",
    "        self.majority_value = np.argmax(counts)\n",
    "        self.class_distribution = counts / len(targets)\n",
    "\n",
    "        # Build the regression tree\n",
    "        self.root = self._build_tree(features, targets)\n",
    "\n",
    "    def _build_tree(self, X, y):\n",
    "        # Stop if the number of features is below the minimum split\n",
    "        if X.shape[1] < self.min_samples_split or len(np.unique(y)) == 1:\n",
    "            return np.mean(y), None, None, np.mean(y), self.class_distribution[0]\n",
    "\n",
    "        best_feat, best_thresh, best_gain = None, None, -np.inf\n",
    "\n",
    "        # Iterate over all features and possible thresholds to find the best split\n",
    "        for feature in range(X.shape[1]):\n",
    "            unique_vals = np.unique(X[:, feature])\n",
    "            for threshold in unique_vals:\n",
    "                mask = X[:, feature] <= threshold\n",
    "                gain = self._rmse_reduction(y, mask)\n",
    "                if gain > best_gain:\n",
    "                    best_gain, best_feat, best_thresh = gain, feature, threshold\n",
    "\n",
    "        # If no improvement, return a leaf node\n",
    "        if best_gain == -np.inf:\n",
    "            return np.mean(y), None, None, np.mean(y), self.class_distribution[0]\n",
    "\n",
    "        # Split the dataset\n",
    "        left_mask = X[:, best_feat] <= best_thresh\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask])\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask])\n",
    "        left_prob = len(y[left_mask]) / len(y)\n",
    "\n",
    "        return (best_feat, best_thresh, left_subtree, right_subtree, left_prob)\n",
    "\n",
    "    def _rmse(self, values):\n",
    "        return np.sqrt(np.mean((values - np.mean(values)) ** 2))\n",
    "\n",
    "    def _rmse_reduction(self, y, mask):\n",
    "        total_rmse = self._rmse(y)\n",
    "        left_rmse = self._rmse(y[mask])\n",
    "        right_rmse = self._rmse(y[~mask])\n",
    "        weighted_rmse = (len(y[mask]) / len(y)) * left_rmse + (len(y[~mask]) / len(y)) * right_rmse\n",
    "        return total_rmse - weighted_rmse\n",
    "\n",
    "    def prune(self, X_val, y_val):\n",
    "        self.root = self._prune_tree(self.root, X_val, y_val)\n",
    "\n",
    "    def _prune_tree(self, node, X_val, y_val):\n",
    "        if node[1] is None:\n",
    "            return node\n",
    "\n",
    "        feat, thresh, left, right, _ = node\n",
    "        left = self._prune_tree(left, X_val, y_val)\n",
    "        right = self._prune_tree(right, X_val, y_val)\n",
    "        pruned_node = (feat, thresh, left, right, node[4])\n",
    "\n",
    "        current_error = self._evaluate(node, X_val, y_val)\n",
    "        pruned_error = self._evaluate(pruned_node, X_val, y_val)\n",
    "\n",
    "        # If pruning does not worsen the error, keep the pruned node\n",
    "        if pruned_error <= current_error:\n",
    "            return pruned_node\n",
    "        else:\n",
    "            return (np.mean(y_val), None, None, None, node[4])\n",
    "\n",
    "    def _evaluate(self, node, X, y):\n",
    "        preds = self._predict_batch(X, node)\n",
    "        return np.mean((y - preds) ** 2)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_single(sample, self.root) for sample in X])\n",
    "\n",
    "    def _predict_single(self, sample, node):\n",
    "        if node[1] is None:\n",
    "            return node[0]\n",
    "        feature, threshold, left, right, _ = node\n",
    "        if not np.isnan(sample[feature]):\n",
    "            if sample[feature] <= threshold:\n",
    "                return self._predict_single(sample, left)\n",
    "            else:\n",
    "                return self._predict_single(sample, right)\n",
    "        else:\n",
    "            return self.majority_value\n",
    "\n",
    "    def _predict_batch(self, X, node):\n",
    "        preds = np.array([self._predict_single(sample, node) for sample in X])\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavel\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\pavel\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE до обрезки: 2112.1791806705496\n",
      "MSE после обрезки: 2112.1791806705496\n",
      "\n",
      "Замеры времени выполнения:\n",
      "Обучение модели: 0.3450 секунд\n",
      "Предсказание до обрезки: 0.0030 секунд\n",
      "Обрезка дерева: 0.4034 секунд\n",
      "Предсказание после обрезки: 0.0000 секунд\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(path + '/Titanic-Dataset.csv')\n",
    "\n",
    "preprocess_start = time.time()\n",
    "\n",
    "features = df[['Pclass', 'Age', 'Embarked',]].copy()\n",
    "target = df['Fare'].values\n",
    "\n",
    "# features['Sex'] = features['Sex'].map({'male': 0, 'female': 1})\n",
    "features['Embarked'] = features['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "features['Age'].fillna(features['Age'].mean(), inplace=True)\n",
    "features['Embarked'].fillna(features['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "features['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "\n",
    "X = features.values\n",
    "y = target\n",
    "preprocess_time = time.time() - preprocess_start\n",
    "\n",
    "split_start = time.time()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "split_time = time.time() - split_start\n",
    "\n",
    "# Замер времени обучения модели\n",
    "train_start = time.time()\n",
    "tree_reg = TreeRegressor(min_samples_split=2)\n",
    "tree_reg.train(X_train, y_train)\n",
    "train_time = time.time() - train_start\n",
    "\n",
    "predict_before_start = time.time()\n",
    "predictions = tree_reg.predict(X_val)\n",
    "\n",
    "# print(\"Предсказанные значения до обрезки:\", predictions)\n",
    "# print(\"Фактические значения:\", y_val)\n",
    "\n",
    "predict_before_time = time.time() - predict_before_start\n",
    "\n",
    "prune_start = time.time()\n",
    "\n",
    "pruned_tree = deepcopy(tree_reg)\n",
    "pruned_tree.prune(X_val, y_val)\n",
    "pruned_predictions = pruned_tree.predict(X_val)\n",
    "\n",
    "# print(\"Предсказанные значения после обрезки:\", pruned_predictions)\n",
    "# print(\"Фактические значения:\", y_val)\n",
    "\n",
    "prune_time = time.time() - prune_start\n",
    "\n",
    "predict_after_start = time.time()\n",
    "predict_after_time = time.time() - predict_after_start\n",
    "\n",
    "evaluate_start = time.time()\n",
    "\n",
    "mse_before = mean_squared_error(y_val, predictions)\n",
    "mse_after = mean_squared_error(y_val, pruned_predictions)\n",
    "print(f\"MSE до обрезки: {mse_before}\")\n",
    "print(f\"MSE после обрезки: {mse_after}\")\n",
    "evaluate_time = time.time() - evaluate_start\n",
    "\n",
    "print(\"\\nЗамеры времени выполнения:\")\n",
    "print(f\"Обучение модели: {train_time:.4f} секунд\")\n",
    "print(f\"Предсказание до обрезки: {predict_before_time:.4f} секунд\")\n",
    "print(f\"Обрезка дерева: {prune_time:.4f} секунд\")\n",
    "print(f\"Предсказание после обрезки: {predict_after_time:.4f} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 0.0020 секунд\n",
      "Время предсказания: 0.0000 секунд\n",
      "MSE: 2469.4859128214207\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "from sklearn.tree import DecisionTreeRegressor as SklearnDecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "# Замер времени обучения scikit-learn модели\n",
    "sklearn_train_start = time.time()\n",
    "sklearn_tree = SklearnDecisionTreeRegressor(min_samples_split=2, random_state=42)\n",
    "sklearn_tree.fit(X_train, y_train)\n",
    "sklearn_train_time = time.time() - sklearn_train_start\n",
    "\n",
    "# Замер времени предсказания scikit-learn модели\n",
    "sklearn_predict_start = time.time()\n",
    "sklearn_predictions = sklearn_tree.predict(X_val)\n",
    "sklearn_predict_time = time.time() - sklearn_predict_start\n",
    "\n",
    "# Замер времени оценки качества scikit-learn модели\n",
    "sklearn_evaluate_start = time.time()\n",
    "sklearn_mse = mean_squared_error(y_val, sklearn_predictions)\n",
    "sklearn_evaluate_time = time.time() - sklearn_evaluate_start\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Время обучения: {sklearn_train_time:.4f} секунд\")\n",
    "print(f\"Время предсказания: {sklearn_predict_time:.4f} секунд\")\n",
    "print(f\"MSE: {sklearn_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
