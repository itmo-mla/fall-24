{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f7f023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea55b4b",
   "metadata": {},
   "source": [
    "# Загрузка датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9154b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_and_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc2915ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Age', 'Fare', 'Sex', 'sibsp', 'Parch', 'Embarked', '2urvived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97724426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>2urvived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1307.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.503186</td>\n",
       "      <td>33.281086</td>\n",
       "      <td>0.355997</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>1.492731</td>\n",
       "      <td>0.261268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.905241</td>\n",
       "      <td>51.741500</td>\n",
       "      <td>0.478997</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>0.814626</td>\n",
       "      <td>0.439494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>31.275000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age         Fare          Sex        sibsp        Parch  \\\n",
       "count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000   \n",
       "mean     29.503186    33.281086     0.355997     0.498854     0.385027   \n",
       "std      12.905241    51.741500     0.478997     1.041658     0.865560   \n",
       "min       0.170000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%      22.000000     7.895800     0.000000     0.000000     0.000000   \n",
       "50%      28.000000    14.454200     0.000000     0.000000     0.000000   \n",
       "75%      35.000000    31.275000     1.000000     1.000000     0.000000   \n",
       "max      80.000000   512.329200     1.000000     8.000000     9.000000   \n",
       "\n",
       "          Embarked     2urvived  \n",
       "count  1307.000000  1309.000000  \n",
       "mean      1.492731     0.261268  \n",
       "std       0.814626     0.439494  \n",
       "min       0.000000     0.000000  \n",
       "25%       1.000000     0.000000  \n",
       "50%       2.000000     0.000000  \n",
       "75%       2.000000     1.000000  \n",
       "max       2.000000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb132481",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['2urvived'], axis=1)\n",
    "target = data['2urvived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd332864",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('possum.csv')\n",
    "\n",
    "features = data.drop(columns=['hdlngth', 'case', 'Pop'], axis=1)\n",
    "target = data['hdlngth']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for col in ['site', 'sex']:\n",
    "    features[col] = le.fit_transform(features[col])\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(features, target, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f0da0",
   "metadata": {},
   "source": [
    "# Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a3f1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    compare_df = pd.DataFrame({'y': list(y_test), 'y_pred': y_pred})\n",
    "    \n",
    "    TP = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 1)]\n",
    "    FP = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 1)]\n",
    "    FN = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 0)]\n",
    "    TN = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 0)]\n",
    "    \n",
    "    return (len(TP) + len(TN)) / len(compare_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241b9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precession\n",
    "\n",
    "def precession(y_test, y_pred):\n",
    "    compare_df = pd.DataFrame({'y': list(y_test), 'y_pred': y_pred})\n",
    "    \n",
    "    TP = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 1)]\n",
    "    FP = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 1)]\n",
    "    FN = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 0)]\n",
    "    TN = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 0)]\n",
    "    \n",
    "    return len(TP) / (len(TP) + len(FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc81f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall\n",
    "\n",
    "def recall(y_test, y_pred):\n",
    "    compare_df = pd.DataFrame({'y': list(y_test), 'y_pred': y_pred})\n",
    "    \n",
    "    TP = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 1)]\n",
    "    FP = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 1)]\n",
    "    FN = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 0)]\n",
    "    TN = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 0)]\n",
    "    \n",
    "    return len(TP) / (len(TP) + len(FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09686cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1\n",
    "\n",
    "def f1(y_test, y_pred):\n",
    "    compare_df = pd.DataFrame({'y': list(y_test), 'y_pred': y_pred})\n",
    "    \n",
    "    TP = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 1)]\n",
    "    FP = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 1)]\n",
    "    FN = compare_df.loc[(compare_df['y'] == 1) & (compare_df['y_pred'] == 0)]\n",
    "    TN = compare_df.loc[(compare_df['y'] == 0) & (compare_df['y_pred'] == 0)]\n",
    "    \n",
    "    precession_ = precession(y_test, y_pred)\n",
    "    recall_ = recall(y_test, y_pred)\n",
    "    return 2 * precession_ * recall_ / (recall_+ precession_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "913e7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse\n",
    "def mse(y_pred, y_targ):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_targ = np.array(y_targ)\n",
    "    return np.mean(np.square(y_targ - y_pred))\n",
    "\n",
    "# rmse\n",
    "def rmse(y_pred, y_targ):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_targ = np.array(y_targ)\n",
    "    return (np.sum((y_targ - y_pred) ** 2) / len(y_test)) ** 0.5\n",
    "\n",
    "# r2\n",
    "def r2(y_pred, y_targ):\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_targ = np.array(y_targ)\n",
    "    \n",
    "    sse = np.sum((y_pred - y_targ) ** 2)\n",
    "    sst = np.sum((y_pred - np.mean(y_pred)) ** 2)\n",
    "    return abs(1 - sse / sst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1175e17",
   "metadata": {},
   "source": [
    "# Алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46882148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, prediction=None, left_proba=None):\n",
    "        self.feature = feature  # индекс признака\n",
    "        self.threshold = threshold  # порог для разбиения\n",
    "        self.left = left  # левый дочерний узел\n",
    "        self.right = right  # правый дочерний узел\n",
    "        self.prediction = prediction  # предсказание для листового узла\n",
    "        self.left_proba = left_proba\n",
    "        self.num_elems = 0\n",
    "\n",
    "\n",
    "class DecisionTreeID3Classifier:\n",
    "    def __init__(self, max_depth, method, prun=False):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.method = method\n",
    "        self.probas = {}\n",
    "        self.max_proba = 0\n",
    "        self.majority = None\n",
    "        self.prun = prun\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in set(y):\n",
    "            self.probas[i] = len(y.loc[y == i]) / len(y)\n",
    "\n",
    "        self.root = self.build_tree(np.array(X), np.array(y), 0)\n",
    "\n",
    "        self.majority = y.value_counts().argmax()\n",
    "\n",
    "    def predict_instance(self, node, sample):\n",
    "        if np.nan not in sample:\n",
    "            if node.prediction is not None:\n",
    "                node.num_elems += 1\n",
    "                return node.prediction\n",
    "            else:\n",
    "                if sample[node.feature] <= node.threshold:\n",
    "                    node.num_elems += 1\n",
    "                    return self.predict_instance(node.left, sample)\n",
    "                else:\n",
    "                    node.num_elems += 1\n",
    "                    return self.predict_instance(node.right, sample)\n",
    "        else:\n",
    "            if node.feature is None:\n",
    "                return node.prediction\n",
    "            else:\n",
    "                return self.count_nan(node, sample, 0)\n",
    "\n",
    "    def pruning(self, node):\n",
    "        if node.num_elems == 0:\n",
    "            node.prediction = self.majority\n",
    "        else:\n",
    "            if node.prediction is None:\n",
    "                self.pruning(node.left)\n",
    "                self.pruning(node.right)\n",
    "\n",
    "    def count_nan(self, node, sample, proba):\n",
    "        if node.prediction is not None:\n",
    "            if self.max_proba < proba * self.probas[int(node.prediction)]:\n",
    "                self.max_proba = proba * self.probas[int(node.prediction)]\n",
    "                return self.probas[int(node.prediction)]\n",
    "        else:\n",
    "            if proba != 0:\n",
    "                self.count_nan(node.left, sample, node.left_proba*proba)\n",
    "                self.count_nan(node.right, sample, (1-node.left_proba)*proba)\n",
    "            else:\n",
    "                self.count_nan(node.left, sample, node.left_proba)\n",
    "                self.count_nan(node.right, sample, (1 - node.left_proba))\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = [self.predict_instance(self.root, sample) for sample in np.array(X)]\n",
    "        if self.prun is True:\n",
    "            self.pruning(self.root)\n",
    "            pred = [self.predict_instance(self.root, sample) for sample in np.array(X)]\n",
    "            return pred\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    @staticmethod\n",
    "    def entropy(y):\n",
    "        counter = Counter(y)\n",
    "        total_instances = len(y)\n",
    "        return -sum((count / total_instances) * math.log2(count / total_instances) for count in counter.values())\n",
    "\n",
    "    @staticmethod\n",
    "    def donskoy(y, left_mask, right_mask):\n",
    "        left = {}\n",
    "        right = {}\n",
    "        delta = 0\n",
    "\n",
    "        for i in set(y):\n",
    "            left[i] = len(pd.Series(y[left_mask]).loc[pd.Series(y[left_mask]) == i])\n",
    "            right[i] = len(pd.Series(y[right_mask]).loc[pd.Series(y[right_mask]) == i])\n",
    "        if len(left.keys()) >= len(right.keys()):\n",
    "            for key, value in left.items():\n",
    "                if key in right.keys():\n",
    "                    delta += value * right[key]\n",
    "        else:\n",
    "            for key, value in right.items():\n",
    "                if key in left.keys():\n",
    "                    delta += value * left[key]\n",
    "        return delta\n",
    "\n",
    "    def information_gain(self, y, x_column, threshold):\n",
    "        left_mask = x_column <= threshold\n",
    "        right_mask = x_column > threshold\n",
    "        n_total = len(y)\n",
    "\n",
    "        if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "            return 0, 0\n",
    "\n",
    "        n_left = len(y[left_mask])\n",
    "        n_right = len(y[right_mask])\n",
    "        left_proba = n_left / n_total\n",
    "        delta = 0\n",
    "\n",
    "        if self.method == 'entropy':\n",
    "            parent = self.entropy(y)\n",
    "            child = (n_left / n_total) * self.entropy(y[left_mask]) + (n_right / n_total) * self.entropy(y[right_mask])\n",
    "            delta = parent - child\n",
    "        else:\n",
    "            delta = self.donskoy(y, left_mask, right_mask)\n",
    "                \n",
    "        return delta, left_proba\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_proba_left = None\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            thresholds = set(X[:, feature])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain, left_proba = self.information_gain(y, X[:, feature], threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_proba_left = left_proba\n",
    "\n",
    "        return best_feature, best_threshold, best_proba_left\n",
    "\n",
    "    def build_tree(self, X, y, depth):\n",
    "        # Если все примеры принадлежат одному классу\n",
    "        if len(set(y)) == 1:\n",
    "            return Node(prediction=y[0])\n",
    "\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return Node(prediction=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        # Если нет признаков для разбиения\n",
    "        if X.shape[1] == 0:\n",
    "            return Node(prediction=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        # Находим лучший признак и порог\n",
    "        feature, threshold, left_proba = self.best_split(X, y)\n",
    "\n",
    "        if feature is None:\n",
    "            return Node(prediction=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        left_mask = X[:, feature] <= threshold\n",
    "        right_mask = X[:, feature] > threshold\n",
    "\n",
    "        left_node = self.build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_node = self.build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return Node(feature=feature, threshold=threshold, left=left_node, right=right_node, left_proba=left_proba)\n",
    "\n",
    "    \n",
    "class DecisionTreeID3Regressor:\n",
    "    def __init__(self, max_depth, prun=False):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth\n",
    "        self.probas = {}\n",
    "        self.max_proba = 0\n",
    "        self.majority = None\n",
    "        self.prun = prun\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for i in set(y):\n",
    "            self.probas[i] = len(y.loc[y == i]) / len(y)\n",
    "\n",
    "        self.root = self.build_tree(np.array(X), np.array(y), 0)\n",
    "\n",
    "        self.majority = y.value_counts().argmax()\n",
    "\n",
    "    def predict_instance(self, node, sample):\n",
    "        if np.nan not in sample:\n",
    "            if node.prediction is not None:\n",
    "                node.num_elems += 1\n",
    "                return node.prediction\n",
    "            else:\n",
    "                if sample[node.feature] <= node.threshold:\n",
    "                    return self.predict_instance(node.left, sample)\n",
    "                else:\n",
    "                    return self.predict_instance(node.right, sample)\n",
    "        else:\n",
    "            if node.feature is None:\n",
    "                return node.prediction\n",
    "            else:\n",
    "                return self.count_nan(node, sample, 0)\n",
    "\n",
    "    def pruning(self, node):\n",
    "        if node.num_elems == 0:\n",
    "            node.prediction = self.majority\n",
    "        else:\n",
    "            self.pruning(node.left)\n",
    "            self.pruning(node.right)\n",
    "\n",
    "    def count_nan(self, node, sample, proba):\n",
    "        if node.prediction is not None:\n",
    "            if self.max_proba < proba * self.probas[int(node.prediction)]:\n",
    "                self.max_proba = proba * self.probas[int(node.prediction)]\n",
    "                return self.probas[int(node.prediction)]\n",
    "        else:\n",
    "            if proba != 0:\n",
    "                self.count_nan(node.left, sample, node.left_proba*proba)\n",
    "                self.count_nan(node.right, sample, (1-node.left_proba)*proba)\n",
    "            else:\n",
    "                self.count_nan(node.left, sample, node.left_proba)\n",
    "                self.count_nan(node.right, sample, (1 - node.left_proba))\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = [self.predict_instance(self.root, sample) for sample in np.array(X)]\n",
    "        self.pruning(self.root)\n",
    "        return pred\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_mse(left, right):\n",
    "        total_samples = len(left) + len(right)\n",
    "        mean_left = np.mean(left) if len(left) > 0 else 0\n",
    "        mean_right = np.mean(right) if len(right) > 0 else 0\n",
    "\n",
    "        mse_left = np.sum((left - mean_left) ** 2) if len(left) > 0 else 0\n",
    "        mse_right = np.sum((right - mean_right) ** 2) if len(right) > 0 else 0\n",
    "\n",
    "        return (mse_left + mse_right) / total_samples\n",
    "\n",
    "    def information_gain(self, y, x_column, threshold):\n",
    "        left_mask = x_column <= threshold\n",
    "        right_mask = x_column > threshold\n",
    "        n_total = len(y)\n",
    "\n",
    "        if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n",
    "            return 0, 0\n",
    "\n",
    "        n_left = len(y[left_mask])\n",
    "        left_proba = n_left / n_total\n",
    "\n",
    "        delta = self.calculate_mse(y[left_mask], y[right_mask])\n",
    "\n",
    "        return delta, left_proba\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_proba_left = None\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            thresholds = set(X[:, feature])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain, left_proba = self.information_gain(y, X[:, feature], threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_proba_left = left_proba\n",
    "\n",
    "        return best_feature, best_threshold, best_proba_left\n",
    "\n",
    "    def build_tree(self, X, y, depth):\n",
    "        # Если все принадлежат одному классу\n",
    "        if len(set(y)) == 1:\n",
    "            return Node(prediction=y[0])\n",
    "\n",
    "        if self.max_depth is not None and depth >= self.max_depth:\n",
    "            return Node(prediction=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        # Если нет признаков для разбиения\n",
    "        if X.shape[1] == 0:\n",
    "            return Node(prediction=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        # Находим лучший признак и порог\n",
    "        feature, threshold, left_proba = self.best_split(X, y)\n",
    "\n",
    "        if feature is None:\n",
    "            return Node(prediction=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "        left_mask = X[:, feature] <= threshold\n",
    "        right_mask = X[:, feature] > threshold\n",
    "\n",
    "        left_node = self.build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_node = self.build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        return Node(feature=feature, threshold=threshold, left=left_node, right=right_node, left_proba=left_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431ef32",
   "metadata": {},
   "source": [
    "# Расчет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9a593",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d9804",
   "metadata": {},
   "source": [
    "***Энтропийный критерий***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb624d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 500 ms\n",
      "Wall time: 772 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# с прунингом\n",
    "tree = DecisionTreeID3Classifier(method='entropy', max_depth=7, prun=True)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74b00099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8\n",
      "recall: 0.54\n",
      "precession: 0.6\n",
      "f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {round(accuracy(y_test, y_pred), 2)}')\n",
    "print(f'recall: {round(recall(y_test, y_pred), 2)}')\n",
    "print(f'precession: {round(precession(y_test, y_pred), 2)}')\n",
    "print(f'f1: {round(f1(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38dce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 744 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree = DecisionTreeID3Classifier(method='entropy', max_depth=7)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9807acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8\n",
      "recall: 0.54\n",
      "precession: 0.6\n",
      "f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {round(accuracy(y_test, y_pred), 2)}')\n",
    "print(f'recall: {round(recall(y_test, y_pred), 2)}')\n",
    "print(f'precession: {round(precession(y_test, y_pred), 2)}')\n",
    "print(f'f1: {round(f1(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161b9dde",
   "metadata": {},
   "source": [
    "***Критерий Донского***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d01d30b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.94 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeID3Classifier(method='donskoy', max_depth=15)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9530e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.66\n",
      "recall: 0.28\n",
      "precession: 0.3\n",
      "f1: 0.29\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {round(accuracy(y_test, y_pred), 2)}')\n",
    "print(f'recall: {round(recall(y_test, y_pred), 2)}')\n",
    "print(f'precession: {round(precession(y_test, y_pred), 2)}')\n",
    "print(f'f1: {round(f1(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f8e3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.19 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeID3Classifier(method='donskoy', max_depth=15, prun=True)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d862bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.66\n",
      "recall: 0.28\n",
      "precession: 0.3\n",
      "f1: 0.29\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {round(accuracy(y_test, y_pred), 2)}')\n",
    "print(f'recall: {round(recall(y_test, y_pred), 2)}')\n",
    "print(f'precession: {round(precession(y_test, y_pred), 2)}')\n",
    "print(f'f1: {round(f1(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8cc828",
   "metadata": {},
   "source": [
    "***Автоматический алгоритм***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21596965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 15.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree_auto = DecisionTreeClassifier(random_state=0, max_depth=8)\n",
    "tree_auto.fit(X_train, y_train)\n",
    "y_pred_auto = tree_auto.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42141e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8\n",
      "recall: 0.53\n",
      "precession: 0.59\n",
      "f1: 0.56\n"
     ]
    }
   ],
   "source": [
    "print(f'accuracy: {round(accuracy(y_test, y_pred_auto), 2)}')\n",
    "print(f'recall: {round(recall(y_test, y_pred_auto), 2)}')\n",
    "print(f'precession: {round(precession(y_test, y_pred_auto), 2)}')\n",
    "print(f'f1: {round(f1(y_test, y_pred_auto), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa277bf",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25cdcd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree = DecisionTreeID3Regressor(max_depth=10, prun=True)\n",
    "tree.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = tree.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f837ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.83\n",
      "rmse: 0.39\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(np.array(y_pred_reg).reshape(-1, 1))\n",
    "y_pred_reg = scaler.transform(np.array(y_pred_reg).reshape(-1, 1))\n",
    "\n",
    "scaler.fit(np.array(y_test_reg).reshape(-1, 1))\n",
    "y_test_reg = scaler.transform(np.array(y_test_reg).reshape(-1, 1))\n",
    "\n",
    "print(f'mse: {round(mse(y_pred_reg, y_test_reg), 2)}')\n",
    "print(f'rmse: {round(rmse(y_pred_reg, y_test_reg), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2c4089d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tree = DecisionTreeID3Regressor(max_depth=10)\n",
    "tree.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = tree.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6574b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.83\n",
      "rmse: 0.39\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(np.array(y_pred_reg).reshape(-1, 1))\n",
    "y_pred_reg = scaler.transform(np.array(y_pred_reg).reshape(-1, 1))\n",
    "\n",
    "scaler.fit(np.array(y_test_reg).reshape(-1, 1))\n",
    "y_test_reg = scaler.transform(np.array(y_test_reg).reshape(-1, 1))\n",
    "\n",
    "print(f'mse: {round(mse(y_pred_reg, y_test_reg), 2)}')\n",
    "print(f'rmse: {round(rmse(y_pred_reg, y_test_reg), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a10062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 7.46 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree_auto = DecisionTreeRegressor(random_state=0, max_depth=10)\n",
    "tree_auto.fit(X_train_reg, y_train_reg)\n",
    "y_pred_auto = tree_auto.predict(X_test_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61d41515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.7\n",
      "rmse: 0.24\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(np.array(y_pred_auto).reshape(-1, 1))\n",
    "y_pred_auto = scaler.transform(np.array(y_pred_auto).reshape(-1, 1))\n",
    "\n",
    "scaler.fit(np.array(y_test_reg).reshape(-1, 1))\n",
    "y_test_reg = scaler.transform(np.array(y_test_reg).reshape(-1, 1))\n",
    "\n",
    "print(f'mse: {round(mse(y_pred_auto, y_test_reg), 2)}')\n",
    "print(f'rmse: {round(rmse(y_pred_auto, y_test_reg), 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
