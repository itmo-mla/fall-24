{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from graphviz import Digraph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>FBS</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Family History of Diabetes</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Diet</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>Normal</td>\n",
       "      <td>100</td>\n",
       "      <td>5.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Regular</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>High</td>\n",
       "      <td>120</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>High</td>\n",
       "      <td>140</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>High</td>\n",
       "      <td>160</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>Normal</td>\n",
       "      <td>80</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Regular</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>17</td>\n",
       "      <td>Female</td>\n",
       "      <td>15</td>\n",
       "      <td>Normal</td>\n",
       "      <td>100</td>\n",
       "      <td>5.7</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Normal</td>\n",
       "      <td>120</td>\n",
       "      <td>6.4</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>High</td>\n",
       "      <td>140</td>\n",
       "      <td>7.1</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>High</td>\n",
       "      <td>160</td>\n",
       "      <td>7.8</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>37</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>High</td>\n",
       "      <td>180</td>\n",
       "      <td>8.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Gender  BMI Blood Pressure  FBS  HbA1c Family History of Diabetes  \\\n",
       "0     45    Male   25         Normal  100    5.7                         No   \n",
       "1     55  Female   30           High  120    6.4                        Yes   \n",
       "2     65    Male   35           High  140    7.1                        Yes   \n",
       "3     75  Female   40           High  160    7.8                        Yes   \n",
       "4     40    Male   20         Normal   80    5.0                         No   \n",
       "..   ...     ...  ...            ...  ...    ...                        ...   \n",
       "123   17  Female   15         Normal  100    5.7                         No   \n",
       "124   22    Male   19         Normal  120    6.4                         No   \n",
       "125   27  Female   24           High  140    7.1                         No   \n",
       "126   32    Male   29           High  160    7.8                         No   \n",
       "127   37  Female   34           High  180    8.5                         No   \n",
       "\n",
       "    Smoking     Diet Exercise Diagnosis  \n",
       "0        No  Healthy  Regular        No  \n",
       "1       Yes     Poor       No       Yes  \n",
       "2       Yes     Poor       No       Yes  \n",
       "3       Yes     Poor       No       Yes  \n",
       "4        No  Healthy  Regular        No  \n",
       "..      ...      ...      ...       ...  \n",
       "123     Yes     Poor       No       Yes  \n",
       "124     Yes     Poor       No       Yes  \n",
       "125     Yes     Poor       No       Yes  \n",
       "126     Yes     Poor       No       Yes  \n",
       "127     Yes     Poor       No       Yes  \n",
       "\n",
       "[128 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/sujithmandala/easiest-diabetes-classification-dataset\n",
    "df_class = pd.read_csv('../cl_dataset.csv')\n",
    "df_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/mirichoi0218/insurance\n",
    "df_reg = pd.read_csv('../reg_dataset.csv')\n",
    "df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_missing_values(df, missing_percent=0.02, exclude_column='column'):\n",
    "    \"\"\"\n",
    "    Вводит пропущенные значения в DataFrame.\n",
    "\n",
    "    Параметры:\n",
    "    df (pd.DataFrame): Исходный DataFrame.\n",
    "    missing_percent (float): Процент значений, которые будут заменены на NaN.\n",
    "    exclude_column (str): Название столбца, который будет исключен из процесса ввода пропущенных значений.\n",
    "\n",
    "    Возвращает:\n",
    "    pd.DataFrame: DataFrame с введенными пропущенными значениями.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    n_rows, n_cols = df.shape\n",
    "\n",
    "    total_values = n_rows * n_cols\n",
    "\n",
    "    n_missing = max(1, int(total_values * missing_percent))\n",
    "\n",
    "    exclude_index = df.columns.get_loc(exclude_column)\n",
    "\n",
    "    for _ in range(n_missing):\n",
    "        i = random.randint(0, n_rows - 1)\n",
    "        j = random.randint(0, n_cols - 1)\n",
    "\n",
    "        while j == exclude_index:\n",
    "            j = random.randint(0, n_cols - 1)\n",
    "\n",
    "        df.iat[i, j] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_missing = introduce_missing_values(df_class, missing_percent=0.08, exclude_column='Diagnosis')\n",
    "df_reg_missing = introduce_missing_values(df_reg, missing_percent=0.08, exclude_column='charges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaler(df, cols_to_scale):\n",
    "    \"\"\"\n",
    "    Масштабирует указанные столбцы DataFrame с использованием Min-Max нормализации.\n",
    "\n",
    "    Параметры:\n",
    "    df (pd.DataFrame): Исходный DataFrame.\n",
    "    cols_to_scale (list): Список столбцов, которые нужно масштабировать.\n",
    "\n",
    "    Возвращает:\n",
    "    pd.DataFrame: DataFrame с масштабированными столбцами.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in cols_to_scale:\n",
    "        col_min = df[col].min()\n",
    "        col_max = df[col].max()\n",
    "\n",
    "        if col_max - col_min != 0:\n",
    "            df[col] = (df[col] - col_min) / (col_max - col_min)\n",
    "        else:\n",
    "            df[col] = 0.5\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_clean_norm = minmax_scaler(\n",
    "    df_class_missing, \n",
    "    cols_to_scale=[\"Age\", \"BMI\", \"FBS\", \"HbA1c\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_clean_norm = minmax_scaler(\n",
    "    df_reg_missing, \n",
    "    cols_to_scale=[\"age\", \"bmi\", \"children\", \"charges\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    \"\"\"\n",
    "    Вычисляет энтропию для заданного набора меток.\n",
    "\n",
    "    Параметры:\n",
    "    labels: Набор меток.\n",
    "\n",
    "    Возвращает:\n",
    "    float: Значение энтропии.\n",
    "    \"\"\"\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    ent = 0.0\n",
    "    # вычисляем энтропию для каждой метки\n",
    "    for _, cnt in counts.items():\n",
    "        p = cnt / total  # вероятность метки\n",
    "        # учитываем только положительные вероятности, чтобы избежать логарифма от нуля\n",
    "        ent -= p * np.log2(p) if p > 0 else 0\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donskoy_criterion(labels):\n",
    "    \"\"\"\n",
    "    Вычисляет критерий Донского для заданного набора меток.\n",
    "\n",
    "    Параметры:\n",
    "    labels (list or array-like): Набор меток.\n",
    "\n",
    "    Возвращает:\n",
    "    float: Значение критерия Донского.\n",
    "    \"\"\"\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    res = 1.0\n",
    "    for _, cnt in counts.items():\n",
    "        p = cnt / total  # вероятность метки\n",
    "        res -= p**2  # уменьшаем результат на квадрат вероятности\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_criterion(y_values):\n",
    "    possible_values = np.unique(y_values)\n",
    "    mse_list = [np.mean((y_values - y)**2) for y in possible_values]\n",
    "    return min(mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(current_labels, split_labels_list, criterion_function):\n",
    "    parent_criterion = criterion_function(current_labels)\n",
    "    total = len(current_labels)\n",
    "    weighted_sum = 0.0\n",
    "    for child_labels in split_labels_list:\n",
    "        child_len = len(child_labels)\n",
    "        weighted_sum += (child_len / total) * criterion_function(child_labels)\n",
    "    return parent_criterion - weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, \n",
    "                feature_name=None,\n",
    "                threshold=None,\n",
    "                left=None,\n",
    "                right=None,\n",
    "                leaf_value=None):\n",
    "        self.feature_name = feature_name\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.leaf_value = leaf_value\n",
    "        \n",
    "    def is_leaf(self):\n",
    "        return self.leaf_value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_id3(X, y, features, criterion_function, depth=0, max_depth=None, is_regression=False):\n",
    "    \"\"\"\n",
    "    Строит дерево решений с использованием алгоритма ID3.\n",
    "\n",
    "    Параметры:\n",
    "    X (pd.DataFrame): Матрица признаков.\n",
    "    y (pd.Series): Вектор меток.\n",
    "    features (list): Список признаков для рассмотрения.\n",
    "    criterion_function (callable): Функция критерия для вычисления информационного прироста.\n",
    "    depth (int): Текущая глубина дерева.\n",
    "    max_depth (int): Максимальная глубина дерева.\n",
    "    is_regression (bool): Флаг, указывающий, является ли задача регрессией.\n",
    "\n",
    "    Возвращает:\n",
    "    DecisionNode: Корневой узел дерева решений.\n",
    "    \"\"\"\n",
    "\n",
    "    # если все метки одинаковы, возвращаем листовой узел с этой меткой\n",
    "    if len(set(y)) == 1:\n",
    "        return DecisionNode(leaf_value=y.iloc[0])\n",
    "\n",
    "    # если признаки закончились или достигнута максимальная глубина, возвращаем листовой узел\n",
    "    if len(features) == 0 or (max_depth is not None and depth >= max_depth):\n",
    "        if is_regression:\n",
    "            return DecisionNode(leaf_value=np.mean(y))\n",
    "        else:\n",
    "            return DecisionNode(leaf_value=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    best_gain = -1\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    best_splits = None\n",
    "\n",
    "    # проходим по каждому признаку\n",
    "    for feat in features:\n",
    "        unique_values = X[feat].dropna().unique()  # исключаем NaN из уникальных значений\n",
    "\n",
    "        # если признак числовой\n",
    "        if X[feat].dtype in [float, int]:\n",
    "            if len(unique_values) == 0:\n",
    "                continue  # все значения пропущены\n",
    "            threshold_candidates = [np.mean(unique_values)]\n",
    "        else:\n",
    "            threshold_candidates = list(unique_values) + [np.nan]\n",
    "\n",
    "        # проходим по каждому кандидату на порог\n",
    "        for t in threshold_candidates:\n",
    "            if X[feat].dtype in [float, int]:\n",
    "                left_mask = X[feat] <= t\n",
    "                right_mask = X[feat] > t\n",
    "                left_mask = left_mask | X[feat].isna()\n",
    "            else:\n",
    "                left_mask = X[feat] == t\n",
    "                right_mask = X[feat] != t\n",
    "                left_mask = left_mask | X[feat].isna()\n",
    "\n",
    "            left_labels = y[left_mask]\n",
    "            right_labels = y[right_mask]\n",
    "\n",
    "            if len(left_labels) == 0 or len(right_labels) == 0:\n",
    "                continue  # некорректный сплит\n",
    "\n",
    "            # вычисляем информационный прирост для текущего разбиения\n",
    "            current_gain = information_gain(y, [left_labels, right_labels], criterion_function)\n",
    "            if current_gain > best_gain:\n",
    "                best_gain = current_gain\n",
    "                best_feature = feat\n",
    "                best_threshold = t\n",
    "                best_splits = (left_mask, right_mask)\n",
    "\n",
    "    # если лучший прирост меньше порога, возвращаем листовой узел\n",
    "    if best_gain < 1e-6:\n",
    "        if is_regression:\n",
    "            return DecisionNode(leaf_value=np.mean(y))\n",
    "        else:\n",
    "            return DecisionNode(leaf_value=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    left_mask, right_mask = best_splits\n",
    "    left_node = build_tree_id3(X[left_mask], y[left_mask], features, criterion_function,\n",
    "                            depth+1, max_depth, is_regression)\n",
    "    right_node = build_tree_id3(X[right_mask], y[right_mask], features, criterion_function,\n",
    "                            depth+1, max_depth, is_regression)\n",
    "\n",
    "    # возвращаем узел решения с лучшим признаком и порогом\n",
    "    return DecisionNode(feature_name=best_feature,\n",
    "                        threshold=best_threshold,\n",
    "                        left=left_node,\n",
    "                        right=right_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_id3(x, node):\n",
    "    \"\"\"\n",
    "    Предсказывает метку для одного примера с использованием дерева решений ID3.\n",
    "\n",
    "    Параметры:\n",
    "    x (pd.Series): Пример для предсказания.\n",
    "    node (DecisionNode): Текущий узел дерева решений.\n",
    "\n",
    "    Возвращает:\n",
    "    any: Предсказанная метка.\n",
    "    \"\"\"\n",
    "\n",
    "    # если текущий узел является листом, возвращаем его значение\n",
    "    if node.is_leaf():\n",
    "        return node.leaf_value\n",
    "\n",
    "    feature = node.feature_name\n",
    "    threshold = node.threshold\n",
    "    value = x[feature]\n",
    "\n",
    "    # если значение признака пропущено, идем в левое поддерево\n",
    "    if pd.isna(value):\n",
    "        return predict_one_id3(x, node.left)\n",
    "\n",
    "    # если порог является числом\n",
    "    if isinstance(threshold, float) or isinstance(threshold, int):\n",
    "        if value <= threshold:\n",
    "            return predict_one_id3(x, node.left)\n",
    "        else:\n",
    "            return predict_one_id3(x, node.right)\n",
    "    else:\n",
    "        # если порог является категориальным значением\n",
    "        if value == threshold:\n",
    "            return predict_one_id3(x, node.left)\n",
    "        else:\n",
    "            return predict_one_id3(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_id3(X, tree_root):\n",
    "    \"\"\"\n",
    "    Предсказывает метки для всех примеров в матрице признаков с использованием дерева решений ID3.\n",
    "\n",
    "    Параметры:\n",
    "    X (pd.DataFrame): Матрица признаков.\n",
    "    tree_root (DecisionNode): Корневой узел дерева решений.\n",
    "\n",
    "    Возвращает:\n",
    "    np.array: Массив предсказанных меток.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = []\n",
    "    \n",
    "    # проходим по каждому примеру в матрице признаков\n",
    "    for i in range(len(X)):\n",
    "        x = X.iloc[i]  # извлекаем текущий пример\n",
    "        preds.append(predict_one_id3(x, tree_root))  # предсказываем метку для текущего примера\n",
    "\n",
    "    # возвращаем массив предсказанных меток\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_final = df_class_clean_norm.copy()\n",
    "df_class_final[\"Diagnosis\"] = df_class_final[\"Diagnosis\"].apply(lambda x: 1 if x == \"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_cols(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_final = encode_categorical_cols(df_class_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = df_class_final.drop(\"Diagnosis\", axis=1)\n",
    "y_class = df_class_final[\"Diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_class, y_class, test_size=0.3, random_state=42, stratify=y_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tree_entropy = build_tree_id3(X_train_c, y_train_c, features=X_train_c.columns,\n",
    "                            criterion_function=entropy, max_depth=None, is_regression=False)\n",
    "time_entropy = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tree_donskoy = build_tree_id3(X_train_c, y_train_c, features=X_train_c.columns,\n",
    "                            criterion_function=donskoy_criterion, max_depth=None, is_regression=False)\n",
    "time_donskoy = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_entropy = predict_id3(X_test_c, tree_entropy)\n",
    "y_pred_donskoy = predict_id3(X_test_c, tree_donskoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.821\n",
      "Precision: 0.750\n",
      "Recall:    0.333\n",
      "F1-score:  0.462\n",
      "Time:      0.111018 sec\n",
      "\n",
      "Accuracy:  0.821\n",
      "Precision: 0.750\n",
      "Recall:    0.333\n",
      "F1-score:  0.462\n",
      "Time:      0.087565 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_e, prec_e, rec_e, f1_e = classification_metrics(y_test_c, y_pred_entropy)\n",
    "print(f\"Accuracy:  {acc_e:.3f}\")\n",
    "print(f\"Precision: {prec_e:.3f}\")\n",
    "print(f\"Recall:    {rec_e:.3f}\")\n",
    "print(f\"F1-score:  {f1_e:.3f}\")\n",
    "print(f\"Time:      {time_entropy:.6f} sec\\n\")\n",
    "\n",
    "acc_d, prec_d, rec_d, f1_d = classification_metrics(y_test_c, y_pred_donskoy)\n",
    "print(f\"Accuracy:  {acc_d:.3f}\")\n",
    "print(f\"Precision: {prec_d:.3f}\")\n",
    "print(f\"Recall:    {rec_d:.3f}\")\n",
    "print(f\"F1-score:  {f1_d:.3f}\")\n",
    "print(f\"Time:      {time_donskoy:.6f} sec\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sklearn = DecisionTreeClassifier(criterion=\"entropy\", random_state=42, max_depth=None)  \n",
    "start_time = time.time()\n",
    "clf_sklearn.fit(X_train_c, y_train_c)\n",
    "time_sklearn = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = clf_sklearn.predict(X_test_c)\n",
    "acc_s, prec_s, rec_s, f1_s = classification_metrics(y_test_c, y_pred_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.949\n",
      "Precision: 1.000\n",
      "Recall:    0.778\n",
      "F1-score:  0.875\n",
      "Time:      0.002330 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy:  {acc_s:.3f}\")\n",
    "print(f\"Precision: {prec_s:.3f}\")\n",
    "print(f\"Recall:    {rec_s:.3f}\")\n",
    "print(f\"F1-score:  {f1_s:.3f}\")\n",
    "print(f\"Time:      {time_sklearn:.6f} sec\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_final = df_reg_clean_norm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_final = encode_categorical_cols(df_reg_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg = df_reg_final.drop(\"charges\", axis=1)\n",
    "y_reg = df_reg_final[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tree_reg = build_tree_id3(X_train_r, y_train_r, features=X_train_r.columns,\n",
    "                        criterion_function=mse_criterion, max_depth=None, is_regression=True)\n",
    "time_reg_id3 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_id3 = predict_id3(X_test_r, tree_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_id3 = mean_squared_error(y_test_r, y_pred_reg_id3)\n",
    "r2_id3 = r2_score(y_test_r, y_pred_reg_id3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.021217\n",
      "R^2:  0.432076\n",
      "Time: 11.640545 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE:  {mse_id3:.6f}\")\n",
    "print(f\"R^2:  {r2_id3:.6f}\")\n",
    "print(f\"Time: {time_reg_id3:.6f} sec\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sklearn = DecisionTreeRegressor(criterion=\"squared_error\", max_depth=None, random_state=42)\n",
    "start_time = time.time()\n",
    "reg_sklearn.fit(X_train_r, y_train_r)\n",
    "time_sklearn_reg = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_sklearn = reg_sklearn.predict(X_test_r)\n",
    "mse_sklearn = mean_squared_error(y_test_r, y_pred_reg_sklearn)\n",
    "r2_sklearn = r2_score(y_test_r, y_pred_reg_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.013279\n",
      "R^2:  0.644536\n",
      "Time: 0.002199 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE:  {mse_sklearn:.6f}\")\n",
    "print(f\"R^2:  {r2_sklearn:.6f}\")\n",
    "print(f\"Time: {time_sklearn_reg:.6f} sec\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_tree(node, X_val, y_val, is_regression=False):\n",
    "    \"\"\"\n",
    "    Обрезка дерева решений с использованием валидационного набора данных.\n",
    "\n",
    "    Параметры:\n",
    "    node (DecisionNode): Текущий узел дерева решений.\n",
    "    X_val (pd.DataFrame): Валидационная матрица признаков.\n",
    "    y_val (pd.Series): Валидационный вектор меток.\n",
    "    is_regression (bool): Флаг, указывающий, является ли задача регрессией. По умолчанию False.\n",
    "\n",
    "    Возвращает:\n",
    "    DecisionNode: Обрезанный узел дерева решений.\n",
    "    \"\"\"\n",
    "\n",
    "    if node.is_leaf():\n",
    "        return node\n",
    "\n",
    "    # если валидационный набор пуст, возвращаем текущий узел\n",
    "    if len(X_val) == 0 or len(y_val) == 0:\n",
    "        return node\n",
    "\n",
    "    # если левый дочерний узел существует, то рекурсивно обрезаем его\n",
    "    if node.left is not None:\n",
    "        feat = node.feature_name\n",
    "        threshold = node.threshold\n",
    "        if pd.isna(threshold):\n",
    "            mask_left = X_val[feat].isna()\n",
    "        elif isinstance(threshold, (float, int)):\n",
    "            mask_left = (X_val[feat] <= threshold) | X_val[feat].isna()\n",
    "        else:\n",
    "            mask_left = (X_val[feat] == threshold) | X_val[feat].isna()\n",
    "        X_val_left = X_val[mask_left]\n",
    "        y_val_left = y_val[mask_left]\n",
    "        node.left = prune_tree(node.left, X_val_left, y_val_left, is_regression)\n",
    "\n",
    "    # если правый дочерний узел существует, то рекурсивно обрезаем его\n",
    "    if node.right is not None:\n",
    "        feat = node.feature_name\n",
    "        threshold = node.threshold\n",
    "        if pd.isna(threshold):\n",
    "            mask_right = ~X_val[feat].isna()\n",
    "        elif isinstance(threshold, (float, int)):\n",
    "            mask_right = X_val[feat] > threshold\n",
    "        else:\n",
    "            mask_right = X_val[feat] != threshold\n",
    "        X_val_right = X_val[mask_right]\n",
    "        y_val_right = y_val[mask_right]\n",
    "        node.right = prune_tree(node.right, X_val_right, y_val_right, is_regression)\n",
    "\n",
    "    # предсказываем метки до обрезки\n",
    "    preds_before = predict_id3(X_val, node)\n",
    "    if is_regression:\n",
    "        error_before = mean_squared_error(y_val, preds_before)\n",
    "    else:\n",
    "        acc_before = accuracy_score(y_val, preds_before)\n",
    "        error_before = 1 - acc_before\n",
    "\n",
    "    # сохраняем текущие дочерние узлы и признак\n",
    "    left_backup = node.left\n",
    "    right_backup = node.right\n",
    "    feature_backup = node.feature_name\n",
    "    threshold_backup = node.threshold\n",
    "\n",
    "    # определяем значение листа\n",
    "    if is_regression:\n",
    "        leaf_value = np.mean(y_val) if len(y_val) > 0 else 0\n",
    "    else:\n",
    "        leaf_value = Counter(y_val).most_common(1)[0][0] if len(y_val) > 0 else 0\n",
    "\n",
    "    # превращаем текущий узел в лист\n",
    "    node.left = None\n",
    "    node.right = None\n",
    "    node.feature_name = None\n",
    "    node.threshold = None\n",
    "    node.leaf_value = leaf_value\n",
    "\n",
    "    # предсказываем метки после обрезки\n",
    "    preds_after = predict_id3(X_val, node)\n",
    "    if is_regression:\n",
    "        error_after = mean_squared_error(y_val, preds_after)\n",
    "    else:\n",
    "        acc_after = accuracy_score(y_val, preds_after)\n",
    "        error_after = 1 - acc_after\n",
    "\n",
    "    # если ошибка увеличилась, то восстанавливаем исходные дочерние узлы и признак\n",
    "    if error_after > error_before:\n",
    "        node.left = left_backup\n",
    "        node.right = right_backup\n",
    "        node.feature_name = feature_backup\n",
    "        node.threshold = threshold_backup\n",
    "        node.leaf_value = None\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_metrics(name, tree, X_test, y_test):\n",
    "    print(f\"\\n{name})\")\n",
    "\n",
    "    y_pred = predict_id3(X_test, tree)\n",
    "    acc, prec, rec, f1 = classification_metrics(y_test, y_pred)\n",
    "\n",
    "    pruned_tree = prune_tree(copy.deepcopy(tree), X_test, y_test, is_regression=False)\n",
    "\n",
    "    y_pred_pruned = predict_id3(X_test, pruned_tree)\n",
    "    acc_pruned, prec_pruned, rec_pruned, f1_pruned = classification_metrics(y_test, y_pred_pruned)\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'],\n",
    "        'Before Pruning': [acc, prec, rec, f1],\n",
    "        'After Pruning': [acc_pruned, prec_pruned, rec_pruned, f1_pruned]\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df.set_index('Metric', inplace=True)\n",
    "\n",
    "    print(metrics_df)\n",
    "\n",
    "    return pruned_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Tree, entropy)\n",
      "           Before Pruning  After Pruning\n",
      "Metric                                  \n",
      "Accuracy         0.820513       0.974359\n",
      "Precision        0.750000       1.000000\n",
      "Recall           0.333333       0.888889\n",
      "F1-score         0.461538       0.941176\n",
      "\n",
      "Classification Tree, Donskoy)\n",
      "           Before Pruning  After Pruning\n",
      "Metric                                  \n",
      "Accuracy         0.820513       0.974359\n",
      "Precision        0.750000       1.000000\n",
      "Recall           0.333333       0.888889\n",
      "F1-score         0.461538       0.941176\n"
     ]
    }
   ],
   "source": [
    "tree_entropy_pruned = print_classification_metrics(\"Classification Tree, entropy\", tree_entropy, X_test_c, y_test_c)\n",
    "tree_donskoy_pruned = print_classification_metrics(\"Classification Tree, Donskoy\", tree_donskoy, X_test_c, y_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE before pruning: 0.021217, after: 0.008563\n",
      "R^2 before pruning: 0.432076, after: 0.770781\n"
     ]
    }
   ],
   "source": [
    "tree_reg_pruned = prune_tree(copy.deepcopy(tree_reg), X_test_r, y_test_r, is_regression=True)\n",
    "y_pred_reg_pruned = predict_id3(X_test_r, tree_reg_pruned)\n",
    "mse_id3_pruned = mean_squared_error(y_test_r, y_pred_reg_pruned)\n",
    "r2_id3_pruned = r2_score(y_test_r, y_pred_reg_pruned)\n",
    "\n",
    "print(f\"MSE before pruning: {mse_id3:.6f}, after: {mse_id3_pruned:.6f}\")\n",
    "print(f\"R^2 before pruning: {r2_id3:.6f}, after: {r2_id3_pruned:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(tree, name=\"tree\"):\n",
    "    \"\"\"\n",
    "    Визуализирует дерево решений с использованием Graphviz.\n",
    "\n",
    "    Параметры:\n",
    "    tree (DecisionNode): Корневой узел дерева решений.\n",
    "    name (str): Имя графа. По умолчанию \"tree\".\n",
    "\n",
    "    Возвращает:\n",
    "    Digraph: Объект графа Graphviz.\n",
    "    \"\"\"\n",
    "\n",
    "    dot = Digraph(name=name, format=\"png\")\n",
    "    node_counter = [0]\n",
    "\n",
    "    def add_node(node, parent=None, edge_label=\"\"):\n",
    "        \"\"\"\n",
    "        Рекурсивно добавляет узлы и ребра в граф.\n",
    "\n",
    "        Параметры:\n",
    "        node (DecisionNode): Текущий узел дерева решений.\n",
    "        parent (str): Идентификатор родительского узла. По умолчанию None.\n",
    "        edge_label (str): Метка ребра. По умолчанию пустая строка.\n",
    "        \"\"\"\n",
    "\n",
    "        # если текущий узел является листом, то добавляем его в граф\n",
    "        if node.is_leaf():\n",
    "            node_id = str(node_counter[0])\n",
    "            dot.node(node_id, label=f\"Leaf\\nValue: {node.leaf_value}\", shape=\"box\", style=\"filled\", color=\"lightgrey\")\n",
    "            if parent is not None:\n",
    "                dot.edge(str(parent), node_id, label=edge_label)\n",
    "            node_counter[0] += 1\n",
    "            return\n",
    "\n",
    "        # добавляем текущий узел в граф\n",
    "        node_id = str(node_counter[0])\n",
    "        dot.node(node_id, label=f\"{node.feature_name} <= {node.threshold:.2f}\")\n",
    "        if parent is not None:\n",
    "            dot.edge(str(parent), node_id, label=edge_label)\n",
    "        node_counter[0] += 1\n",
    "\n",
    "        # рекурсивно добавляем дочерние узлы\n",
    "        add_node(node.left, parent=node_id, edge_label=\"Yes\")\n",
    "        add_node(node.right, parent=node_id, edge_label=\"No\")\n",
    "\n",
    "    # начинаем добавление узлов с корневого узла\n",
    "    add_node(tree)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../assets/Entropy_Before_Pruning.png'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_entropy = visualize_tree(tree_entropy, name=\"Entropy_Before_Pruning\")\n",
    "dot_entropy.render(\"Entropy_Before_Pruning\", \"../assets\", cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../assets/Entropy_After_Pruning.png'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_entropy_pruned = visualize_tree(tree_entropy_pruned, name=\"Entropy_After_Pruning\")\n",
    "dot_entropy_pruned.render(\"Entropy_After_Pruning\", \"../assets\", cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../assets/Donskoy_Before_Pruning.png'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_donskoy = visualize_tree(tree_donskoy, name=\"Donskoy_Before_Pruning\")\n",
    "dot_donskoy.render(\"Donskoy_Before_Pruning\", \"../assets\", cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../assets/Donskoy_After_Pruning.png'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_donskoy_pruned = visualize_tree(tree_donskoy_pruned, name=\"Donskoy_After_Pruning\")\n",
    "dot_donskoy_pruned.render(\"Donskoy_After_Pruning\", \"../assets\", cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.471129 to fit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../assets/Regression_Before_Pruning.png'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_regression = visualize_tree(tree_reg, name=\"Regression_Before_Pruning\")\n",
    "dot_regression.render(\"Regression_Before_Pruning\", \"../assets\", cleanup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../assets/Regression_After_Pruning.png'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_regression_pruned = visualize_tree(tree_reg_pruned, name=\"Regression_After_Pruning\")\n",
    "dot_regression_pruned.render(\"Regression_After_Pruning\", \"../assets\", cleanup=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
